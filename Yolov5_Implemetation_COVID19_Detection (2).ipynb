{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QyS8vxpyiGQK"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eA5pPA6blw14"
   },
   "source": [
    "**This notebook contains code for implementing yolo-v5 which helps us to provide the bounding boxes for the test-images.Here we will be working on image level for making the predictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B-bcDABviVe0",
    "outputId": "af3318f3-2db2-4340-8634-7da8f13ad89e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YlS2dHYi7u1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import yaml\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GCICOCd7qm9"
   },
   "outputs": [],
   "source": [
    "pip install -q --upgrade wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nx7WuYlx7toh"
   },
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "MA75QBpV7wOf",
    "outputId": "2a87751e-bdec-40ec-8ab1-3b3e189ed648"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBAXz6EJUR6s",
    "outputId": "8dde0c68-0be4-462a-bd8c-72f7a78f4f9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.9.0+cu102 (Tesla K80)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iFdaIeqnNjL"
   },
   "source": [
    "**First step is to merge the df at both study and test level so as to get a combined df along with the labels for the bounding boxes.Here at image level there are only two classes availaible which are either opacity or none**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pw3c5rRJihVC",
    "outputId": "a34d4c89-0e4b-4ade-c563-c656806b2775"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/MyDrive/train_image_level.csv.zip\n",
      "  inflating: train_image_level.csv   \n"
     ]
    }
   ],
   "source": [
    "!unzip '/content/drive/MyDrive/train_image_level.csv.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yz9WIrLei3fG"
   },
   "outputs": [],
   "source": [
    "train_image_level=pd.read_csv('/content/train_image_level.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8MT6qqAWjCSV"
   },
   "outputs": [],
   "source": [
    "train_study_level=pd.read_csv('/content/drive/MyDrive/train_study_level.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Hyjllv3jK7b"
   },
   "outputs": [],
   "source": [
    "train_study_level['id']=train_study_level.apply(lambda x:x['id'].split('_')[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53OWUPx2mnKH"
   },
   "outputs": [],
   "source": [
    "train_study_level.rename(columns={'id':'StudyInstanceUID'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrGPDq40jMrF"
   },
   "outputs": [],
   "source": [
    "train_df=pd.merge(train_image_level,train_study_level,how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hVQNO566jxrD"
   },
   "outputs": [],
   "source": [
    "meta_train=pd.read_csv('/content/drive/MyDrive/meta_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "lxTqJSN7nBk2",
    "outputId": "5c1a67fb-ce27-404e-a4e1-a32445d0cfd0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>000a312787f2</td>\n",
       "      <td>3488</td>\n",
       "      <td>4256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559</th>\n",
       "      <td>000c3a3f293f</td>\n",
       "      <td>2320</td>\n",
       "      <td>2832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4034</th>\n",
       "      <td>0012ff7358bc</td>\n",
       "      <td>2544</td>\n",
       "      <td>3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3122</th>\n",
       "      <td>001398f4ff4f</td>\n",
       "      <td>3520</td>\n",
       "      <td>4280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>001bd15d1891</td>\n",
       "      <td>2800</td>\n",
       "      <td>3408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5186</th>\n",
       "      <td>ffcc6edd9445</td>\n",
       "      <td>4240</td>\n",
       "      <td>3480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>ffd91a2c4ca0</td>\n",
       "      <td>2800</td>\n",
       "      <td>3408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>ffd9b6cf2961</td>\n",
       "      <td>2388</td>\n",
       "      <td>3050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>ffdc682f7680</td>\n",
       "      <td>3488</td>\n",
       "      <td>4256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4567</th>\n",
       "      <td>ffe942c8655f</td>\n",
       "      <td>1140</td>\n",
       "      <td>1387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6054 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          image_id  dim0  dim1\n",
       "2067  000a312787f2  3488  4256\n",
       "3559  000c3a3f293f  2320  2832\n",
       "4034  0012ff7358bc  2544  3056\n",
       "3122  001398f4ff4f  3520  4280\n",
       "4241  001bd15d1891  2800  3408\n",
       "...            ...   ...   ...\n",
       "5186  ffcc6edd9445  4240  3480\n",
       "1305  ffd91a2c4ca0  2800  3408\n",
       "3069  ffd9b6cf2961  2388  3050\n",
       "3191  ffdc682f7680  3488  4256\n",
       "4567  ffe942c8655f  1140  1387\n",
       "\n",
       "[6054 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train_sort=meta_train.sort_values(by='image_id')\n",
    "meta_train_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "goaavdv9npeP"
   },
   "outputs": [],
   "source": [
    "meta_train_sort['image_id']=meta_train_sort.apply(lambda x:x['image_id']+'_image',axis=1)\n",
    "meta_train_sort.rename(columns={'image_id':'id'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "418FApcxnQ_I"
   },
   "outputs": [],
   "source": [
    "final_train_df=pd.merge(train_df,meta_train_sort,how='inner',on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DbXl1aZqnk0q"
   },
   "outputs": [],
   "source": [
    "final_train_df['image_level']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6yenrzhsoMgD"
   },
   "outputs": [],
   "source": [
    "for ind in final_train_df.index:\n",
    "  label=final_train_df['label'][ind].split(' ')[0]\n",
    "  if label=='opacity':\n",
    "    final_train_df['image_level'][ind]=1\n",
    "\n",
    "  else:\n",
    "    final_train_df['image_level'][ind]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DgcHNZUvp2jg"
   },
   "outputs": [],
   "source": [
    "final_train_df.to_csv('final_train_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8iuYMvEh5_V"
   },
   "outputs": [],
   "source": [
    "final_train_df=pd.read_csv('/content/drive/MyDrive/final_train_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_ZUD6Xknqtk"
   },
   "source": [
    "**This is the final dataframe after combining train and study level.The image level is 1 for opacity and 0 for none.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "id": "SMs3AC_6p5GS",
    "outputId": "444dd891-2995-481a-d600-d7bd3cc26d3d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Negative for Pneumonia</th>\n",
       "      <th>Typical Appearance</th>\n",
       "      <th>Indeterminate Appearance</th>\n",
       "      <th>Atypical Appearance</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "      <th>image_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2_image</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3488</td>\n",
       "      <td>4256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2320</td>\n",
       "      <td>2832</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc_image</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2544</td>\n",
       "      <td>3056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001398f4ff4f_image</td>\n",
       "      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.000...</td>\n",
       "      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n",
       "      <td>28dddc8559b2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3520</td>\n",
       "      <td>4280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001bd15d1891_image</td>\n",
       "      <td>[{'x': 623.23328, 'y': 1050, 'width': 714, 'he...</td>\n",
       "      <td>opacity 1 623.23328 1050 1337.23328 2156 opaci...</td>\n",
       "      <td>dfd9fdd85a3e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2800</td>\n",
       "      <td>3408</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  ... image_level\n",
       "0  000a312787f2_image  ...           1\n",
       "1  000c3a3f293f_image  ...           0\n",
       "2  0012ff7358bc_image  ...           1\n",
       "3  001398f4ff4f_image  ...           1\n",
       "4  001bd15d1891_image  ...           1\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUBlmpMOn4pk"
   },
   "source": [
    "**By using stratified k fold we will divide the images into train and valid and will use  yolo-v5 algo for each of the folds.In this way we will come up with five different weights for each of the fold which we will combine it during inference.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TcmLd1wvu3dI"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kdusn0KIy7J1"
   },
   "outputs": [],
   "source": [
    "final_train_df['folds']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zixPE7_gxehC"
   },
   "outputs": [],
   "source": [
    "fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for i,(tr_idx,val_idx) in enumerate(fold.split(final_train_df,final_train_df['image_level'])):\n",
    "  final_train_df['folds'][val_idx]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vm1CyK0QqYLf"
   },
   "outputs": [],
   "source": [
    "!unzip '/content/drive/MyDrive/my_train.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZoiohRloWmA"
   },
   "source": [
    "**Directory Structure**\n",
    "\n",
    "1)Main_Directory_Name-->Datset_folds--->Images--->Train/Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fyLHLDuj8kdY",
    "outputId": "73155b2e-8291-4416-9579-2bbeca63fdd7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4843/4843 [00:00<00:00, 5753.37it/s]\n",
      "100%|██████████| 1211/1211 [00:00<00:00, 5717.66it/s]\n",
      "100%|██████████| 4843/4843 [00:01<00:00, 4750.78it/s]\n",
      "100%|██████████| 1211/1211 [00:00<00:00, 4560.72it/s]\n",
      "100%|██████████| 4843/4843 [00:00<00:00, 5377.37it/s]\n",
      "100%|██████████| 1211/1211 [00:00<00:00, 5427.44it/s]\n",
      "100%|██████████| 4843/4843 [00:00<00:00, 5930.67it/s]\n",
      "100%|██████████| 1211/1211 [00:00<00:00, 6176.40it/s]\n",
      "100%|██████████| 4844/4844 [00:00<00:00, 5059.68it/s]\n",
      "100%|██████████| 1210/1210 [00:00<00:00, 5865.45it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  train_df=final_train_df[final_train_df['folds']!=i]\n",
    "  valid_df=final_train_df[final_train_df['folds']==i]\n",
    "  \n",
    "\n",
    "  \n",
    "\n",
    "  for ind in tqdm(train_df.index):\n",
    "    \n",
    "\n",
    "      filename=train_df['id'][ind].split('_')[0]\n",
    "      filepath='/content/resized_train_data/' + filename + '.jpg'\n",
    "\n",
    "      os.makedirs('/content/covid_19/dataset_folds_{}/images/train'.format(i),exist_ok=True)\n",
    "\n",
    "      copyfile(filepath,'/content/covid_19/dataset_folds_{}/images/train/{}.jpg'.format(i,filename))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "  for ind in tqdm(valid_df.index):\n",
    "    \n",
    "      filename=valid_df['id'][ind].split('_')[0]\n",
    "      filepath='/content/resized_train_data/' + filename + '.jpg'\n",
    "\n",
    "      os.makedirs('/content/covid_19/dataset_folds_{}/images/val'.format(i),exist_ok=True)\n",
    "\n",
    "      copyfile(filepath,'/content/covid_19/dataset_folds_{}/images/val/{}.jpg'.format(i,filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVt0VZLuo6Lu"
   },
   "source": [
    "**Steps for training yolov5**\n",
    "\n",
    "1) Forst we have to cfreate the directory structure as mentioned above\n",
    "\n",
    "2) We have to clone the yolov5 repository and move it along the same directory structure.Further we have to install the requires dependencies using the requirements.txt file\n",
    "\n",
    "3)Now we have to create a yaml file under the same directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VJXsrwAMEC7P",
    "outputId": "375ce86f-1406-4306-efd1-7b345abdbb4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 9362, done.\u001b[K\n",
      "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
      "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
      "remote: Total 9362 (delta 4), reused 9 (delta 4), pack-reused 9352\u001b[K\n",
      "Receiving objects: 100% (9362/9362), 9.71 MiB | 6.29 MiB/s, done.\n",
      "Resolving deltas: 100% (6502/6502), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iGV8E2FcvFRx"
   },
   "outputs": [],
   "source": [
    "pip install -r 'covid_19/yolov5/requirements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tg8cwPpQvWQY"
   },
   "outputs": [],
   "source": [
    "for fold in range(5):\n",
    "\n",
    "  yaml_data={'train':'/content/covid_19/dataset_folds_{}/images/train'.format(fold),\n",
    "  'val':'/content/covid_19/dataset_folds_{}/images/val'.format(fold),\n",
    "  'nc':2,\n",
    "  'names':['none','opacity']}\n",
    "\n",
    "\n",
    "  my_file=open('/content/covid_19/yolov5/data/data_fold_{}.yaml'.format(fold),'w')\n",
    "  yaml.dump(yaml_data,my_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vp-N2XfQyeqk",
    "outputId": "8ff08dd4-6883-4582-edaa-bcfcf4116a44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names: [none, opacity]\n",
      "nc: 2\n",
      "train: /content/covid_19/dataset_folds_2/images/train\n",
      "val: /content/covid_19/dataset_folds_2/images/val\n"
     ]
    }
   ],
   "source": [
    "%cat '/content/covid_19/yolov5/data/data_fold_2.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5R_U17aSp1O_"
   },
   "source": [
    "**After doing all the necessary steps for training yolov5 our next step is towards creating the co-ordinates for the bounding boxes in yolov5 format from given labels.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZ73KR_oqMEt"
   },
   "source": [
    "**As we have resized the image into 256*256 we have to scale the labels accordingly.Here I have made sure that only those images are taken for which the labels are present.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "egRoW3JD4wLX"
   },
   "outputs": [],
   "source": [
    "for ind in tqdm(list(final_train_df[final_train_df['boxes'].notnull()].index)):\n",
    "  final_train_df['boxes'][ind]=eval(final_train_df['boxes'][ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5TbSCgoe5WSx"
   },
   "outputs": [],
   "source": [
    "ind_boxes=final_train_df[final_train_df['boxes'].notnull()].index\n",
    "scaled_dim_final_list=[]\n",
    "for ind in ind_boxes:\n",
    "  scaled_dim_list=[]\n",
    "  scaled_dim_0=final_train_df['dim1'][ind]/256\n",
    "  scaled_dim_1=final_train_df['dim0'][ind]/256\n",
    "  for j in range(len(final_train_df['boxes'][ind])):\n",
    "    scaled_list=[]\n",
    "    scaled_list.append(final_train_df['boxes'][ind][j]['x']/scaled_dim_0)\n",
    "    scaled_list.append(final_train_df['boxes'][ind][j]['y']/scaled_dim_1)\n",
    "    scaled_list.append(final_train_df['boxes'][ind][j]['width']/scaled_dim_0)\n",
    "    scaled_list.append(final_train_df['boxes'][ind][j]['height']/scaled_dim_1)\n",
    "\n",
    "    scaled_dim_list.append(scaled_list)\n",
    "\n",
    "  #print(final_train_df['boxes'][ind][j]['x']/scaled_dim_0)\n",
    "\n",
    "  scaled_dim_final_list.append((scaled_dim_list,ind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fusKefYtq0Ow"
   },
   "source": [
    "**Here we are defining  a function which will transform the coordinates into yolo-v5 format.On ething to keep in ming that the coordinates must be normalized.**\n",
    "\n",
    "**The co-ordinates are xcenter,ycenter,width,height**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLvVu9P7_ub_"
   },
   "outputs": [],
   "source": [
    "def get_yolo_format_boxes(ind,list_dim,df_index):\n",
    "  yolo_boxes=[]\n",
    "  for ind_1,ind_2 in zip(list(ind),range(len(list_dim))):\n",
    "    if ind_1==df_index and list_dim[ind_2][1]==df_index:\n",
    "      for ind_3 in range(len(final_train_df['boxes'][ind_1])):\n",
    "        w=list_dim[ind_2][0][ind_3][2]\n",
    "        h=list_dim[ind_2][0][ind_3][3]\n",
    "        xc=(list_dim[ind_2][0][ind_3][0])+ int(w/2)\n",
    "        yc=(list_dim[ind_2][0][ind_3][1])+ int(h/2)\n",
    "        normalized_coord=[xc/256,yc/256,w/256,h/256]#normalizing the co-ordinates\n",
    "        if (normalized_coord[0])<1 and (normalized_coord[1])<1 and (normalized_coord[2])<1 and (normalized_coord[3])<1:\n",
    "          yolo_boxes.append(normalized_coord)\n",
    "\n",
    "  return yolo_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CtNh3orrX-j"
   },
   "source": [
    "**We also have to create labels for our train and valid images.This will be a text file which will contain the class label followed by bb co-ordinates.For each co-ordinate there will be a line change.**\n",
    "\n",
    "**Directory Structure**\n",
    "\n",
    "Main_Directory_Name--->Dataset_Folds--->labels-->train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-41JrfjpkT3j",
    "outputId": "32cd9a38-e946-4fdd-84c6-6cb3e4fac72d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4843/4843 [00:03<00:00, 1339.12it/s]\n",
      "100%|██████████| 1211/1211 [00:00<00:00, 1226.47it/s]\n",
      "100%|██████████| 4843/4843 [00:03<00:00, 1321.13it/s]\n",
      "100%|██████████| 1211/1211 [00:00<00:00, 1262.10it/s]\n",
      "100%|██████████| 4843/4843 [00:03<00:00, 1318.58it/s]\n",
      "100%|██████████| 1211/1211 [00:00<00:00, 1361.47it/s]\n",
      "100%|██████████| 4843/4843 [00:03<00:00, 1327.78it/s]\n",
      "100%|██████████| 1211/1211 [00:00<00:00, 1322.89it/s]\n",
      "100%|██████████| 4844/4844 [00:03<00:00, 1279.94it/s]\n",
      "100%|██████████| 1210/1210 [00:00<00:00, 1303.22it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  train_df=final_train_df[final_train_df['folds']!=i]\n",
    "  valid_df=final_train_df[final_train_df['folds']==i]\n",
    "\n",
    "  for num in tqdm(train_df.index):\n",
    "\n",
    "    filename=train_df['id'][num].split('_')[0]\n",
    "    os.makedirs('/content/covid_19/dataset_folds_{}/labels/train'.format(i),exist_ok=True)\n",
    "    filepath='/content/covid_19/dataset_folds_{}/labels/train/{}.txt'.format(i,filename)\n",
    "\n",
    "    if train_df['image_level'][num]==1:\n",
    "\n",
    "      yolo_bb=get_yolo_format_boxes(ind_boxes,scaled_dim_final_list,num)\n",
    "      #print(yolo_bb)\n",
    "      with open(filepath,'w') as f:\n",
    "        for ind_bb_yolo in yolo_bb:\n",
    "          yolo_bb_classes=[1]+ind_bb_yolo\n",
    "          yolo_bb_classes=[str(j) for j in yolo_bb_classes]\n",
    "          yolo_bb_classes=' '.join(yolo_bb_classes)\n",
    "          #print(yolo_bb_classes)\n",
    "          f.write(yolo_bb_classes)\n",
    "          f.write('\\n')\n",
    "\n",
    "  for num in tqdm(valid_df.index):\n",
    "\n",
    "    filename=valid_df['id'][num].split('_')[0]\n",
    "    os.makedirs('/content/covid_19/dataset_folds_{}/labels/val'.format(i),exist_ok=True)\n",
    "    filepath='/content/covid_19/dataset_folds_{}/labels/val/{}.txt'.format(i,filename)\n",
    "\n",
    "    if valid_df['image_level'][num]==1:\n",
    "\n",
    "      yolo_bb=get_yolo_format_boxes(ind_boxes,scaled_dim_final_list,num)\n",
    "      #print(yolo_bb)\n",
    "      with open(filepath,'w') as f:\n",
    "        for ind_bb_yolo in yolo_bb:\n",
    "          yolo_bb_classes=[1]+ind_bb_yolo\n",
    "          yolo_bb_classes=[str(j) for j in yolo_bb_classes]\n",
    "          yolo_bb_classes=' '.join(yolo_bb_classes)\n",
    "          #print(yolo_bb_classes)\n",
    "          f.write(yolo_bb_classes)\n",
    "          f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8vmEHJqsCFv"
   },
   "source": [
    "**Finally after doing all the necessary steps we will start training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qETxnojRsN20"
   },
   "outputs": [],
   "source": [
    "#IMG_SIZE-->256\n",
    "#BATCH_SIZE-->256\n",
    "#TRAIN_PATH-->/content/covid_19/yolov5/train.py\n",
    "#EPOCHS-->10\n",
    "#DATA-->/content/covid_19/yolov5/data/data_fold_{i}.yaml\n",
    "#WEIGHTS-->yolov5s.pt\n",
    "#SAVE_PERIOD-->10\n",
    "#PROJECT--->COVID_19_DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tLzqDyoS8s2z",
    "outputId": "680739ec-1a45-4865-f697-e29896aec15a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
      "100% 755k/755k [00:00<00:00, 39.3MB/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/covid_19/yolov5/data/data_fold_0.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=10, batch_size=16, imgsz=256, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=covid_19_detection, entity=None, name=yolov5_final_folds_0, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=10, artifact_alias=latest, local_rank=-1, freeze=0, patience=100\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "YOLOv5 🚀 v5.0-425-g22ee6fb torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir covid_19_detection', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvishal_1996\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov5_final_folds_0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vishal_1996/covid_19_detection\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vishal_1996/covid_19_detection/runs/7kvte7ih\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/wandb/run-20210911_094503-7kvte7ih\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt to yolov5s.pt...\n",
      "100% 14.1M/14.1M [00:00<00:00, 75.6MB/s]\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7066239 parameters, 7066239 gradients, 16.4 GFLOPs\n",
      "\n",
      "Transferred 356/362 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 59 weight, 62 weight (no decay), 62 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/covid_19/dataset_folds_0/labels/train' images and labels...3360 found, 1483 missing, 0 empty, 0 corrupted: 100% 4843/4843 [00:02<00:00, 2023.58it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/covid_19/dataset_folds_0/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/covid_19/dataset_folds_0/labels/val' images and labels...841 found, 370 missing, 0 empty, 0 corrupted: 100% 1211/1211 [00:00<00:00, 1398.83it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/covid_19/dataset_folds_0/labels/val.cache\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Plotting labels... \n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.77, Best Possible Recall (BPR) = 0.9998\n",
      "Image sizes 256 train, 256 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mcovid_19_detection/yolov5_final_folds_0\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.596G   0.08792   0.01857   0.01001        22       256: 100% 303/303 [01:24<00:00,  3.60it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  3.93it/s]\n",
      "                 all       1211       1548      0.232      0.269       0.13     0.0279\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.684G    0.0653   0.01839  0.001013        27       256: 100% 303/303 [01:17<00:00,  3.92it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.03it/s]\n",
      "                 all       1211       1548      0.393      0.418      0.294     0.0714\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.684G   0.06246   0.01771 0.0007648        15       256: 100% 303/303 [01:16<00:00,  3.98it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.06it/s]\n",
      "                 all       1211       1548      0.443       0.39      0.321     0.0689\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.684G   0.06011   0.01775 0.0005935        22       256: 100% 303/303 [01:15<00:00,  3.99it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.12it/s]\n",
      "                 all       1211       1548      0.454      0.445      0.371     0.0976\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.684G   0.05814    0.0175 0.0003962        16       256: 100% 303/303 [01:15<00:00,  3.99it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.18it/s]\n",
      "                 all       1211       1548      0.489      0.409       0.37      0.102\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.684G   0.05669   0.01745 0.0002737        20       256: 100% 303/303 [01:16<00:00,  3.98it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.18it/s]\n",
      "                 all       1211       1548      0.511      0.422      0.384      0.116\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.684G   0.05569   0.01705 0.0002176        21       256: 100% 303/303 [01:15<00:00,  3.99it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.18it/s]\n",
      "                 all       1211       1548      0.569      0.455      0.447      0.132\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.684G   0.05514   0.01722 0.0001724        29       256: 100% 303/303 [01:15<00:00,  4.00it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.18it/s]\n",
      "                 all       1211       1548      0.549      0.459      0.443      0.127\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.684G   0.05429   0.01722 0.0001398        27       256: 100% 303/303 [01:15<00:00,  4.00it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.18it/s]\n",
      "                 all       1211       1548      0.559      0.466      0.453      0.128\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.686G   0.05389   0.01722 0.0001107        21       256: 100% 303/303 [01:15<00:00,  3.99it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:12<00:00,  3.14it/s]\n",
      "                 all       1211       1548      0.611      0.453      0.474      0.133\n",
      "             opacity       1211       1548      0.611      0.453      0.474      0.133\n",
      "\n",
      "10 epochs completed in 0.246 hours.\n",
      "Optimizer stripped from covid_19_detection/yolov5_final_folds_0/weights/last.pt, 14.3MB\n",
      "Optimizer stripped from covid_19_detection/yolov5_final_folds_0/weights/best.pt, 14.3MB\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 420\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /content/wandb/run-20210911_094503-7kvte7ih/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /content/wandb/run-20210911_094503-7kvte7ih/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/box_loss 0.05389\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/obj_loss 0.01722\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/cls_loss 0.00011\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              metrics/precision 0.61133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 metrics/recall 0.45284\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                metrics/mAP_0.5 0.47449\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           metrics/mAP_0.5:0.95 0.13337\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   val/box_loss 0.05718\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   val/obj_loss 0.00886\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   val/cls_loss 0.00011\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          x/lr0 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          x/lr1 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          x/lr2 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       _runtime 913\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     _timestamp 1631354416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          _step 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss █▃▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss █▇▄▄▃▃▁▂▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss █▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision ▁▄▅▅▆▆▇▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall ▁▆▅▇▆▆████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 ▁▄▅▆▆▆▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 ▁▄▄▆▆▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss █▄▄▂▃▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss █▄▄▃▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss █▃▃▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 ▁▅███▇▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 ▁▅███▇▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 █▅▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               _runtime ▁▂▃▃▄▅▆▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             _timestamp ▁▂▃▃▄▅▆▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  _step ▁▂▂▃▄▅▅▆▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 337 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33myolov5_final_folds_0\u001b[0m: \u001b[34mhttps://wandb.ai/vishal_1996/covid_19_detection/runs/7kvte7ih\u001b[0m\n",
      "Results saved to \u001b[1mcovid_19_detection/yolov5_final_folds_0\u001b[0m\n",
      "###################################\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/covid_19/yolov5/data/data_fold_1.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=10, batch_size=16, imgsz=256, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=covid_19_detection, entity=None, name=yolov5_final_folds_1, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=10, artifact_alias=latest, local_rank=-1, freeze=0, patience=100\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "YOLOv5 🚀 v5.0-425-g22ee6fb torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir covid_19_detection', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvishal_1996\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov5_final_folds_1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vishal_1996/covid_19_detection\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vishal_1996/covid_19_detection/runs/3mpjmxja\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/wandb/run-20210911_100028-3mpjmxja\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7066239 parameters, 7066239 gradients, 16.4 GFLOPs\n",
      "\n",
      "Transferred 356/362 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 59 weight, 62 weight (no decay), 62 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/covid_19/dataset_folds_1/labels/train' images and labels...3361 found, 1482 missing, 0 empty, 0 corrupted: 100% 4843/4843 [00:02<00:00, 1972.84it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/covid_19/dataset_folds_1/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/covid_19/dataset_folds_1/labels/val' images and labels...840 found, 371 missing, 0 empty, 0 corrupted: 100% 1211/1211 [00:00<00:00, 1506.73it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/covid_19/dataset_folds_1/labels/val.cache\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Plotting labels... \n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.77, Best Possible Recall (BPR) = 0.9998\n",
      "Image sizes 256 train, 256 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mcovid_19_detection/yolov5_final_folds_1\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.596G   0.08869    0.0186   0.01005        26       256: 100% 303/303 [01:22<00:00,  3.65it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  3.87it/s]\n",
      "                 all       1211       1512      0.326      0.299      0.202      0.048\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.684G     0.066    0.0186   0.00102        23       256: 100% 303/303 [01:16<00:00,  3.95it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.01it/s]\n",
      "                 all       1211       1512      0.295        0.4      0.226     0.0609\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.684G   0.06255   0.01778  0.000769        24       256: 100% 303/303 [01:15<00:00,  4.00it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.10it/s]\n",
      "                 all       1211       1512       0.45      0.351      0.317     0.0771\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.684G    0.0602   0.01781 0.0005939        23       256: 100% 303/303 [01:15<00:00,  4.03it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:08<00:00,  4.24it/s]\n",
      "                 all       1211       1512      0.511      0.445      0.428      0.119\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.684G   0.05844   0.01781 0.0003825        25       256: 100% 303/303 [01:15<00:00,  4.04it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:08<00:00,  4.23it/s]\n",
      "                 all       1211       1512      0.496      0.431      0.398      0.099\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.684G   0.05683   0.01744 0.0002795        20       256: 100% 303/303 [01:15<00:00,  4.03it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.22it/s]\n",
      "                 all       1211       1512       0.47      0.481      0.434      0.112\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.684G   0.05598   0.01745 0.0002178        23       256: 100% 303/303 [01:15<00:00,  4.01it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.22it/s]\n",
      "                 all       1211       1512      0.539      0.459       0.45      0.132\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.684G   0.05489   0.01737 0.0001655        26       256: 100% 303/303 [01:15<00:00,  4.03it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.21it/s]\n",
      "                 all       1211       1512       0.53      0.476      0.461       0.14\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.684G   0.05449   0.01723 0.0001353        22       256: 100% 303/303 [01:15<00:00,  4.01it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.19it/s]\n",
      "                 all       1211       1512      0.636      0.434      0.477      0.134\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.684G   0.05381   0.01717 0.0001147        20       256: 100% 303/303 [01:15<00:00,  4.01it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:12<00:00,  3.16it/s]\n",
      "                 all       1211       1512      0.535      0.515      0.487      0.145\n",
      "             opacity       1211       1512      0.535      0.515      0.487      0.145\n",
      "\n",
      "10 epochs completed in 0.244 hours.\n",
      "Optimizer stripped from covid_19_detection/yolov5_final_folds_1/weights/last.pt, 14.3MB\n",
      "Optimizer stripped from covid_19_detection/yolov5_final_folds_1/weights/best.pt, 14.3MB\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /content/wandb/run-20210911_100028-3mpjmxja/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /content/wandb/run-20210911_100028-3mpjmxja/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/box_loss 0.05381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/obj_loss 0.01717\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/cls_loss 0.00011\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              metrics/precision 0.53502\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 metrics/recall 0.51519\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                metrics/mAP_0.5 0.48711\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           metrics/mAP_0.5:0.95 0.14525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   val/box_loss 0.05626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   val/obj_loss 0.00855\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   val/cls_loss 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          x/lr0 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          x/lr1 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          x/lr2 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       _runtime 899\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     _timestamp 1631355327\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          _step 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss █▃▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss ██▄▄▄▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss █▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision ▂▁▄▅▅▅▆▆█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall ▁▄▃▆▅▇▆▇▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 ▁▂▄▇▆▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 ▁▂▃▆▅▆▇█▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss █▅▆▂▃▃▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss ██▄▃▂▃▂▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss █▄▄▃▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 ▁▅███▇▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 ▁▅███▇▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 █▅▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               _runtime ▁▂▃▃▄▅▆▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             _timestamp ▁▂▃▃▄▅▆▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  _step ▁▂▂▃▄▅▅▆▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 337 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33myolov5_final_folds_1\u001b[0m: \u001b[34mhttps://wandb.ai/vishal_1996/covid_19_detection/runs/3mpjmxja\u001b[0m\n",
      "Results saved to \u001b[1mcovid_19_detection/yolov5_final_folds_1\u001b[0m\n",
      "###################################\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/covid_19/yolov5/data/data_fold_2.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=10, batch_size=16, imgsz=256, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=covid_19_detection, entity=None, name=yolov5_final_folds_2, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=10, artifact_alias=latest, local_rank=-1, freeze=0, patience=100\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "YOLOv5 🚀 v5.0-425-g22ee6fb torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir covid_19_detection', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvishal_1996\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov5_final_folds_2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vishal_1996/covid_19_detection\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vishal_1996/covid_19_detection/runs/r1fk243j\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/wandb/run-20210911_101538-r1fk243j\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7066239 parameters, 7066239 gradients, 16.4 GFLOPs\n",
      "\n",
      "Transferred 356/362 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 59 weight, 62 weight (no decay), 62 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/covid_19/dataset_folds_2/labels/train' images and labels...3361 found, 1482 missing, 0 empty, 0 corrupted: 100% 4843/4843 [00:02<00:00, 1972.03it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/covid_19/dataset_folds_2/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/covid_19/dataset_folds_2/labels/val' images and labels...840 found, 371 missing, 0 empty, 0 corrupted: 100% 1211/1211 [00:00<00:00, 1515.43it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/covid_19/dataset_folds_2/labels/val.cache\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Plotting labels... \n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.77, Best Possible Recall (BPR) = 1.0000\n",
      "Image sizes 256 train, 256 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mcovid_19_detection/yolov5_final_folds_2\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.596G   0.08778   0.01854  0.009983        25       256: 100% 303/303 [01:24<00:00,  3.59it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  3.90it/s]\n",
      "                 all       1211       1557      0.268      0.326      0.163     0.0356\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.684G   0.06525   0.01853  0.001039        21       256: 100% 303/303 [01:17<00:00,  3.91it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.08it/s]\n",
      "                 all       1211       1557      0.382      0.364      0.253     0.0696\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.684G    0.0621   0.01758  0.000761        26       256: 100% 303/303 [01:16<00:00,  3.98it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.21it/s]\n",
      "                 all       1211       1557      0.436      0.342      0.313     0.0757\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.684G    0.0597   0.01775 0.0005661        19       256: 100% 303/303 [01:15<00:00,  3.99it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.21it/s]\n",
      "                 all       1211       1557      0.486      0.432      0.383      0.114\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.684G   0.05797   0.01747 0.0003716        24       256: 100% 303/303 [01:15<00:00,  3.99it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:08<00:00,  4.26it/s]\n",
      "                 all       1211       1557      0.405      0.441      0.326        0.1\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.684G   0.05692   0.01749 0.0002889        17       256: 100% 303/303 [01:15<00:00,  3.99it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.19it/s]\n",
      "                 all       1211       1557      0.472      0.459      0.411      0.123\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.684G   0.05593   0.01714 0.0002209        20       256: 100% 303/303 [01:15<00:00,  3.99it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:08<00:00,  4.23it/s]\n",
      "                 all       1211       1557      0.498      0.468      0.424      0.135\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.684G    0.0546   0.01723 0.0001735        28       256: 100% 303/303 [01:15<00:00,  4.00it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:08<00:00,  4.26it/s]\n",
      "                 all       1211       1557      0.541      0.482      0.442      0.133\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.684G   0.05403   0.01723 0.0001429        22       256: 100% 303/303 [01:15<00:00,  3.99it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:08<00:00,  4.23it/s]\n",
      "                 all       1211       1557      0.534      0.457      0.435      0.138\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.684G   0.05386   0.01692  0.000115        21       256: 100% 303/303 [01:15<00:00,  4.00it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:11<00:00,  3.18it/s]\n",
      "                 all       1211       1557      0.562      0.453      0.449      0.139\n",
      "             opacity       1211       1557      0.562      0.453      0.449      0.139\n",
      "\n",
      "10 epochs completed in 0.245 hours.\n",
      "Optimizer stripped from covid_19_detection/yolov5_final_folds_2/weights/last.pt, 14.3MB\n",
      "Optimizer stripped from covid_19_detection/yolov5_final_folds_2/weights/best.pt, 14.3MB\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1719\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /content/wandb/run-20210911_101538-r1fk243j/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /content/wandb/run-20210911_101538-r1fk243j/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/box_loss 0.05386\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/obj_loss 0.01692\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/cls_loss 0.00012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              metrics/precision 0.5623\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 metrics/recall 0.45279\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                metrics/mAP_0.5 0.44914\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           metrics/mAP_0.5:0.95 0.13928\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   val/box_loss 0.05823\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   val/obj_loss 0.00879\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   val/cls_loss 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          x/lr0 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          x/lr1 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          x/lr2 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       _runtime 906\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     _timestamp 1631356244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          _step 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss █▃▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss ██▄▅▃▃▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss █▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision ▁▄▅▆▄▆▆▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall ▁▃▂▆▆▇▇█▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 ▁▃▅▆▅▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 ▁▃▄▆▅▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss █▇▄▃▃▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss █▅▅▂▃▁▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss █▄▄▃▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 ▁▅███▇▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 ▁▅███▇▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 █▅▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               _runtime ▁▂▃▃▄▅▆▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             _timestamp ▁▂▃▃▄▅▆▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  _step ▁▂▂▃▄▅▅▆▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 337 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33myolov5_final_folds_2\u001b[0m: \u001b[34mhttps://wandb.ai/vishal_1996/covid_19_detection/runs/r1fk243j\u001b[0m\n",
      "Results saved to \u001b[1mcovid_19_detection/yolov5_final_folds_2\u001b[0m\n",
      "###################################\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/covid_19/yolov5/data/data_fold_3.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=10, batch_size=16, imgsz=256, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=covid_19_detection, entity=None, name=yolov5_final_folds_3, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=10, artifact_alias=latest, local_rank=-1, freeze=0, patience=100\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "YOLOv5 🚀 v5.0-425-g22ee6fb torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir covid_19_detection', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvishal_1996\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov5_final_folds_3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vishal_1996/covid_19_detection\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vishal_1996/covid_19_detection/runs/8sfts3h4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/wandb/run-20210911_103055-8sfts3h4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7066239 parameters, 7066239 gradients, 16.4 GFLOPs\n",
      "\n",
      "Transferred 356/362 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 59 weight, 62 weight (no decay), 62 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/covid_19/dataset_folds_3/labels/train' images and labels...3361 found, 1482 missing, 0 empty, 0 corrupted: 100% 4843/4843 [00:02<00:00, 1926.88it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/covid_19/dataset_folds_3/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/covid_19/dataset_folds_3/labels/val' images and labels...840 found, 371 missing, 0 empty, 0 corrupted: 100% 1211/1211 [00:00<00:00, 1367.00it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/covid_19/dataset_folds_3/labels/val.cache\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Plotting labels... \n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.78, Best Possible Recall (BPR) = 0.9998\n",
      "Image sizes 256 train, 256 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mcovid_19_detection/yolov5_final_folds_3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.596G   0.08843    0.0187   0.01011        13       256: 100% 303/303 [01:24<00:00,  3.59it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  3.90it/s]\n",
      "                 all       1211       1536      0.293      0.298      0.194     0.0424\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.684G   0.06532   0.01875  0.001007        22       256: 100% 303/303 [01:17<00:00,  3.91it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.09it/s]\n",
      "                 all       1211       1536      0.406       0.34      0.266     0.0749\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.684G   0.06224   0.01767 0.0007663        15       256: 100% 303/303 [01:16<00:00,  3.96it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.09it/s]\n",
      "                 all       1211       1536      0.467       0.41      0.372     0.0958\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.684G   0.05963   0.01768 0.0005815        20       256: 100% 303/303 [01:16<00:00,  3.97it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.18it/s]\n",
      "                 all       1211       1536      0.454      0.389       0.34     0.0935\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.684G   0.05795   0.01768  0.000392        21       256: 100% 303/303 [01:16<00:00,  3.98it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:08<00:00,  4.25it/s]\n",
      "                 all       1211       1536      0.469      0.469      0.379      0.107\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.684G   0.05625   0.01766 0.0002698        21       256: 100% 303/303 [01:16<00:00,  3.96it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.22it/s]\n",
      "                 all       1211       1536      0.481        0.4      0.358      0.104\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.684G   0.05574   0.01709 0.0002129        19       256: 100% 303/303 [01:16<00:00,  3.97it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:08<00:00,  4.24it/s]\n",
      "                 all       1211       1536      0.601       0.41       0.45      0.125\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.684G   0.05517   0.01738 0.0001726        35       256: 100% 303/303 [01:15<00:00,  3.99it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.21it/s]\n",
      "                 all       1211       1536      0.522       0.49      0.444      0.124\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.684G   0.05464   0.01715 0.0001396        21       256: 100% 303/303 [01:16<00:00,  3.98it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:08<00:00,  4.22it/s]\n",
      "                 all       1211       1536      0.531      0.487      0.476      0.139\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.684G   0.05308   0.01726 0.0001189        20       256: 100% 303/303 [01:16<00:00,  3.96it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:11<00:00,  3.26it/s]\n",
      "                 all       1211       1536      0.524      0.463       0.46      0.128\n",
      "             opacity       1211       1536      0.524      0.463       0.46      0.128\n",
      "\n",
      "10 epochs completed in 0.246 hours.\n",
      "Optimizer stripped from covid_19_detection/yolov5_final_folds_3/weights/last.pt, 14.3MB\n",
      "Optimizer stripped from covid_19_detection/yolov5_final_folds_3/weights/best.pt, 14.3MB\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 2363\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /content/wandb/run-20210911_103055-8sfts3h4/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /content/wandb/run-20210911_103055-8sfts3h4/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/box_loss 0.05308\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/obj_loss 0.01726\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/cls_loss 0.00012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              metrics/precision 0.52361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 metrics/recall 0.46289\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                metrics/mAP_0.5 0.45993\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           metrics/mAP_0.5:0.95 0.12803\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   val/box_loss 0.05783\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   val/obj_loss 0.00887\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   val/cls_loss 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          x/lr0 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          x/lr1 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          x/lr2 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       _runtime 907\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     _timestamp 1631357162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          _step 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss █▃▃▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss ██▃▃▃▃▁▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss █▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision ▁▄▅▅▅▅█▆▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall ▁▃▅▄▇▅▅██▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 ▁▃▅▅▆▅▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 ▁▃▅▅▆▅▇▇█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss █▆▅▄▄▄▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss █▄▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss █▄▄▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 ▁▅███▇▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 ▁▅███▇▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 █▅▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               _runtime ▁▂▃▃▄▅▆▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             _timestamp ▁▂▃▃▄▅▆▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  _step ▁▂▂▃▄▅▅▆▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 337 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33myolov5_final_folds_3\u001b[0m: \u001b[34mhttps://wandb.ai/vishal_1996/covid_19_detection/runs/8sfts3h4\u001b[0m\n",
      "Results saved to \u001b[1mcovid_19_detection/yolov5_final_folds_3\u001b[0m\n",
      "###################################\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/covid_19/yolov5/data/data_fold_4.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=10, batch_size=16, imgsz=256, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=covid_19_detection, entity=None, name=yolov5_final_folds_4, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=10, artifact_alias=latest, local_rank=-1, freeze=0, patience=100\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "YOLOv5 🚀 v5.0-425-g22ee6fb torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir covid_19_detection', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvishal_1996\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov5_final_folds_4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vishal_1996/covid_19_detection\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/vishal_1996/covid_19_detection/runs/1vib5fc2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/wandb/run-20210911_104613-1vib5fc2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7066239 parameters, 7066239 gradients, 16.4 GFLOPs\n",
      "\n",
      "Transferred 356/362 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 59 weight, 62 weight (no decay), 62 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/covid_19/dataset_folds_4/labels/train' images and labels...3361 found, 1483 missing, 0 empty, 0 corrupted: 100% 4844/4844 [00:02<00:00, 1978.67it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/covid_19/dataset_folds_4/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/covid_19/dataset_folds_4/labels/val' images and labels...840 found, 370 missing, 0 empty, 0 corrupted: 100% 1210/1210 [00:00<00:00, 1482.10it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/covid_19/dataset_folds_4/labels/val.cache\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Plotting labels... \n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.76, Best Possible Recall (BPR) = 1.0000\n",
      "Image sizes 256 train, 256 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mcovid_19_detection/yolov5_final_folds_4\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.596G   0.08857    0.0186    0.0101        23       256: 100% 303/303 [01:25<00:00,  3.56it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  3.82it/s]\n",
      "                 all       1210       1528      0.232      0.339      0.166     0.0334\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.684G   0.06535   0.01869  0.001014        21       256: 100% 303/303 [01:18<00:00,  3.85it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.07it/s]\n",
      "                 all       1210       1528      0.388      0.347       0.28     0.0634\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.684G   0.06218   0.01773 0.0007629        28       256: 100% 303/303 [01:17<00:00,  3.92it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.07it/s]\n",
      "                 all       1210       1528      0.416       0.38      0.302     0.0634\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.684G   0.06028   0.01811 0.0005833        23       256: 100% 303/303 [01:16<00:00,  3.98it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.16it/s]\n",
      "                 all       1210       1528      0.314      0.375      0.242     0.0635\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.684G   0.05811    0.0175 0.0004056        23       256: 100% 303/303 [01:16<00:00,  3.94it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.16it/s]\n",
      "                 all       1210       1528      0.453      0.415      0.369     0.0986\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.684G   0.05663   0.01745 0.0002655        28       256: 100% 303/303 [01:16<00:00,  3.96it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.18it/s]\n",
      "                 all       1210       1528      0.507      0.456      0.414      0.121\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.684G   0.05582   0.01701 0.0002068        26       256: 100% 303/303 [01:16<00:00,  3.96it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.20it/s]\n",
      "                 all       1210       1528      0.537      0.436      0.403      0.119\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.684G   0.05505   0.01732 0.0001741        35       256: 100% 303/303 [01:16<00:00,  3.94it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.16it/s]\n",
      "                 all       1210       1528      0.501      0.465      0.405      0.126\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.684G   0.05428   0.01724 0.0001372        19       256: 100% 303/303 [01:16<00:00,  3.97it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:09<00:00,  4.21it/s]\n",
      "                 all       1210       1528      0.515      0.473      0.436      0.129\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.684G   0.05324    0.0171 0.0001112        24       256: 100% 303/303 [01:16<00:00,  3.95it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 38/38 [00:12<00:00,  3.12it/s]\n",
      "                 all       1210       1528      0.527      0.484      0.459      0.138\n",
      "             opacity       1210       1528      0.527      0.484      0.459      0.138\n",
      "\n",
      "10 epochs completed in 0.248 hours.\n",
      "Optimizer stripped from covid_19_detection/yolov5_final_folds_4/weights/last.pt, 14.3MB\n",
      "Optimizer stripped from covid_19_detection/yolov5_final_folds_4/weights/best.pt, 14.3MB\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3011\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /content/wandb/run-20210911_104613-1vib5fc2/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /content/wandb/run-20210911_104613-1vib5fc2/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/box_loss 0.05324\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/obj_loss 0.0171\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/cls_loss 0.00011\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              metrics/precision 0.52719\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 metrics/recall 0.48429\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                metrics/mAP_0.5 0.45904\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           metrics/mAP_0.5:0.95 0.13798\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   val/box_loss 0.05686\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   val/obj_loss 0.00879\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   val/cls_loss 9e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          x/lr0 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          x/lr1 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          x/lr2 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       _runtime 914\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     _timestamp 1631358087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          _step 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss █▃▃▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss ██▄▆▃▃▁▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss █▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision ▁▅▅▃▆▇█▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall ▁▁▃▃▅▇▆▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 ▁▄▄▃▆▇▇▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 ▁▃▃▃▅▇▇▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss █▆▆▇▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss █▆▄▄▄▂▂▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss █▄▄▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 ▁▅███▇▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 ▁▅███▇▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 █▅▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               _runtime ▁▂▃▃▄▅▆▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             _timestamp ▁▂▃▃▄▅▆▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  _step ▁▂▂▃▄▅▅▆▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 337 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33myolov5_final_folds_4\u001b[0m: \u001b[34mhttps://wandb.ai/vishal_1996/covid_19_detection/runs/1vib5fc2\u001b[0m\n",
      "Results saved to \u001b[1mcovid_19_detection/yolov5_final_folds_4\u001b[0m\n",
      "###################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  !python /content/covid_19/yolov5/train.py --img 256 --batch 16 --epochs 10 --data /content/covid_19/yolov5/data/data_fold_{i}.yaml  --weights yolov5s.pt --save_period 10 --project covid_19_detection --name yolov5_final_folds_{i}\n",
    "  print('###################################\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uYIZUUiykkH4"
   },
   "outputs": [],
   "source": [
    "#REF-->https://www.kaggle.com/ayuraj/train-yolov5-cross-validation-ensemble-w-b"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Yolov5_Implemetation_COVID19_Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
